{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42a9cce-dbc2-4edb-98e1-672b93bdc641",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e42a9cce-dbc2-4edb-98e1-672b93bdc641",
    "outputId": "24f40ef6-9871-4a61-e177-02b7672b251d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Importing needed libraries\n",
    "!pip install tensorflow\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, GlobalMaxPooling1D, Dense, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8075d4-9ba1-4407-8fd0-2cd1b9d2c92e",
   "metadata": {
    "id": "1c8075d4-9ba1-4407-8fd0-2cd1b9d2c92e"
   },
   "outputs": [],
   "source": [
    "# Function for cleaning text\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text: normalize spaces, remove misplaced punctuation, fix contractions.\"\"\"\n",
    "    text = str(text).strip().lower()\n",
    "\n",
    "    # Fix spaces around punctuation (keep punctuation but standardize spacing)\n",
    "    text = re.sub(r'\\s+([?.!,\"])', r'\\1', text)  # Removes spaces before punctuation\n",
    "    text = re.sub(r'([?.!,\"])', r'\\1 ', text)  # Ensures one space after punctuation\n",
    "\n",
    "    # Normalize quotes (remove extra surrounding quotes)\n",
    "    text = re.sub(r'^\"|\"$', '', text)\n",
    "\n",
    "    # Handle common contractions\n",
    "    text = re.sub(r\"\\bd'you\\b\", \"do you\", text)\n",
    "    text = re.sub(r\"\\b'cause\\b\", \"because\", text)\n",
    "    text = re.sub(r\"\\bi'm\\b\", \"i am\", text)\n",
    "    text = re.sub(r\"\\bain't\\b\", \"is not\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bS_2QU0bqdu",
   "metadata": {
    "id": "3bS_2QU0bqdu"
   },
   "outputs": [],
   "source": [
    "# Load the vectorizer\n",
    "import pickle\n",
    "with open('vectorizer.pkl', 'rb') as f:\n",
    "      vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5vR5Jk39bWFs",
   "metadata": {
    "id": "5vR5Jk39bWFs"
   },
   "outputs": [],
   "source": [
    "# Define model structure\n",
    "# Defining model's constants\n",
    "max_seq_len = 25\n",
    "embedding_size = 100\n",
    "lstm_units = 300\n",
    "hidden_layer_size = 512\n",
    "\n",
    "# Defining Tensorflow Inputs for sentences\n",
    "premise_input = Input(shape=(max_seq_len,))\n",
    "hypothesis_input = Input(shape=(max_seq_len,))\n",
    "\n",
    "\n",
    "# Defining an Embedding layer based on GLoVe\n",
    "embedding_layer = Embedding(input_dim=len(vectorizer.get_vocabulary()),\n",
    "                            output_dim=embedding_size,\n",
    "                            trainable=True)\n",
    "\n",
    "# Defining function that will be encoding sentences using Embedding layer above and two BiLSTMs\n",
    "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"encode_sentence\")\n",
    "def encode_sentence(input_text):\n",
    "    x = embedding_layer(input_text)\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    return x\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"combine_vectors\")\n",
    "def combine_vectors(inputs):\n",
    "    # inputs is a list of two tensors: [premise_encoded, hypothesis_encoded]\n",
    "    premise, hypothesis = inputs\n",
    "    return tf.concat([premise, hypothesis, tf.abs(premise - hypothesis), premise * hypothesis], axis=1)\n",
    "\n",
    "# Encoding both premise and hypothesis\n",
    "premise_encoded = encode_sentence(premise_input)\n",
    "hypothesis_encoded = encode_sentence(hypothesis_input)\n",
    "\n",
    "joined_vector = Lambda(combine_vectors,\n",
    "                      output_shape=(2400,))([premise_encoded, hypothesis_encoded])\n",
    "\n",
    "# Final Dense layer\n",
    "hidden_layer = Dense(hidden_layer_size, activation='relu')(joined_vector)\n",
    "output = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "model = Model(inputs=[premise_input, hypothesis_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df491f7b-428f-405e-812c-f0cd5a43e7ed",
   "metadata": {
    "id": "df491f7b-428f-405e-812c-f0cd5a43e7ed"
   },
   "outputs": [],
   "source": [
    "# Function to produce a csv file with predictions from a csv file with testing data\n",
    "# Load testing dataset\n",
    "def get_predictions(file_path):\n",
    "  df = pd.read_csv(file_path, quotechar='\"', delimiter=\",\", encoding=\"utf-8\")\n",
    "  df.columns = [\"premise\", \"hypothesis\"]  # Ensure correct column names\n",
    "  df.dropna(inplace=True)  # Remove missing values\n",
    "\n",
    "  # Apply text cleaning for testing dataset\n",
    "  df[\"premise\"] = df[\"premise\"].apply(clean_text)\n",
    "  df[\"hypothesis\"] = df[\"hypothesis\"].apply(clean_text)\n",
    "\n",
    "  # Loading the model\n",
    "  model = tf.keras.models.load_model(\"bilstm_model.keras\")\n",
    "\n",
    "  # Vectorizing the input text\n",
    "  X_premise_loaded = vectorizer(df['premise'].values)\n",
    "  X_hypothesis_loaded = vectorizer(df['hypothesis'].values)\n",
    "\n",
    "  # Produce predictions\n",
    "  y_pred = model.predict([X_premise_loaded, X_hypothesis_loaded])\n",
    "  avg = np.mean(y_pred)\n",
    "  y_pred = (y_pred > avg).astype(int)\n",
    "\n",
    "  # Print model's metrics\n",
    "  print(\"Predictions successfully produced\")\n",
    "\n",
    "  # Save the predictions into a csv file\n",
    "  y_pred = y_pred.flatten()\n",
    "  df_predictions = pd.DataFrame({'prediction': y_pred})\n",
    "\n",
    "  df_predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdafca41-012d-4ae0-8de1-d8121e1a8203",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdafca41-012d-4ae0-8de1-d8121e1a8203",
    "outputId": "f58624fb-05c2-46ac-c072-a8d96a5f3d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 323ms/step\n",
      "Predictions successfully produced\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0792d-b63b-4ce2-bc59-d4e2ca039395",
   "metadata": {
    "id": "84d0792d-b63b-4ce2-bc59-d4e2ca039395"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
