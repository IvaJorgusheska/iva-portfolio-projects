{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2edf8f7-b307-4c7a-9912-5a0edb04fc71",
   "metadata": {
    "id": "e2edf8f7-b307-4c7a-9912-5a0edb04fc71"
   },
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "!pip install tensorflow\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, GlobalMaxPooling1D, Dense, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2170e6a-bd1a-4c96-b959-de38e85d143f",
   "metadata": {
    "id": "b2170e6a-bd1a-4c96-b959-de38e85d143f"
   },
   "outputs": [],
   "source": [
    "# Setting s seed for recreatability\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ba14a0e-127a-45c4-a0aa-42180439686b",
   "metadata": {
    "id": "2ba14a0e-127a-45c4-a0aa-42180439686b"
   },
   "outputs": [],
   "source": [
    "# Define a function for text cleaning\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text: normalize spaces, remove misplaced punctuation, fix contractions.\"\"\"\n",
    "    text = str(text).strip().lower()\n",
    "\n",
    "    # Fix spaces around punctuation (keep punctuation but standardize spacing)\n",
    "    text = re.sub(r'\\s+([?.!,\"])', r'\\1', text)  # Removes spaces before punctuation\n",
    "    text = re.sub(r'([?.!,\"])', r'\\1 ', text)  # Ensures one space after punctuation\n",
    "\n",
    "    # Normalize quotes (remove extra surrounding quotes)\n",
    "    text = re.sub(r'^\"|\"$', '', text)\n",
    "\n",
    "    # Handle common contractions\n",
    "    text = re.sub(r\"\\bd'you\\b\", \"do you\", text)\n",
    "    text = re.sub(r\"\\b'cause\\b\", \"because\", text)\n",
    "    text = re.sub(r\"\\bi'm\\b\", \"i am\", text)\n",
    "    text = re.sub(r\"\\bain't\\b\", \"is not\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5f8940e-b0d1-47d2-b6c0-6c064aee149f",
   "metadata": {
    "id": "a5f8940e-b0d1-47d2-b6c0-6c064aee149f"
   },
   "outputs": [],
   "source": [
    "# WARNING! in order to successfully load the dataset, all csv files have to be in the same directory as ipynb file\n",
    "# Load training dataset\n",
    "df_train = pd.read_csv(\"train.csv\", quotechar='\"', delimiter=\",\", encoding=\"utf-8\")\n",
    "df_train.columns = [\"premise\", \"hypothesis\", \"label\"]  # Ensure correct column names\n",
    "df_train.dropna(inplace=True)  # Remove missing values\n",
    "\n",
    "# Apply text cleaning for training dataset\n",
    "df_train[\"premise\"] = df_train[\"premise\"].apply(clean_text)\n",
    "df_train[\"hypothesis\"] = df_train[\"hypothesis\"].apply(clean_text)\n",
    "\n",
    "df_train[\"label\"] = df_train[\"label\"].astype(int)\n",
    "X_premise_train = df_train['premise'].values\n",
    "X_hypothesis_train = df_train['hypothesis'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec2c56e7-5c6c-44b1-b8e1-9e2ea64af082",
   "metadata": {
    "id": "ec2c56e7-5c6c-44b1-b8e1-9e2ea64af082"
   },
   "outputs": [],
   "source": [
    "# Load validation dataset\n",
    "df_val = pd.read_csv(\"dev.csv\", quotechar='\"', delimiter=\",\", encoding=\"utf-8\")\n",
    "df_val.columns = [\"premise\", \"hypothesis\", \"label\"]  # Ensure correct column names\n",
    "df_val.dropna(inplace=True)  # Remove missing values\n",
    "\n",
    "# Apply text cleaning for validation dataset\n",
    "df_val[\"premise\"] = df_val[\"premise\"].apply(clean_text)\n",
    "df_val[\"hypothesis\"] = df_val[\"hypothesis\"].apply(clean_text)\n",
    "\n",
    "df_val[\"label\"] = df_val[\"label\"].astype(int)\n",
    "\n",
    "X_premise_val = df_val['premise'].values\n",
    "X_hypothesis_val = df_val['hypothesis'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f3cfb7d-a29d-4d97-92db-71636abd440e",
   "metadata": {
    "id": "2f3cfb7d-a29d-4d97-92db-71636abd440e"
   },
   "outputs": [],
   "source": [
    "# Define constants needed for preprocessing\n",
    "max_seq_len = 25\n",
    "\n",
    "# Transform the dataset into the needed format\n",
    "y_train = df_train['label'].values\n",
    "y_val = df_val['label'].values\n",
    "\n",
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=None,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_seq_len)\n",
    "\n",
    "# Adapt the vectorizer to the data\n",
    "combined_data = pd.concat([df_train['premise'], df_train['hypothesis']])\n",
    "vectorizer.adapt(combined_data)\n",
    "\n",
    "# Vectorize input data\n",
    "X_premise_train = vectorizer(X_premise_train)\n",
    "X_hypothesis_train = vectorizer(X_hypothesis_train)\n",
    "\n",
    "X_premise_val = vectorizer(X_premise_val)\n",
    "X_hypothesis_val = vectorizer(X_hypothesis_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52116309-9af5-40a2-8220-2e1ae7ecf707",
   "metadata": {
    "id": "52116309-9af5-40a2-8220-2e1ae7ecf707"
   },
   "outputs": [],
   "source": [
    "# Defining model's constants\n",
    "embedding_size = 100\n",
    "lstm_units = 300\n",
    "hidden_layer_size = 512\n",
    "\n",
    "# Defining Tensorflow Inputs for sentences\n",
    "premise_input = Input(shape=(max_seq_len,))\n",
    "hypothesis_input = Input(shape=(max_seq_len,))\n",
    "\n",
    "# Defining an Embedding layer based on GLoVe\n",
    "embedding_layer = Embedding(input_dim=len(vectorizer.get_vocabulary()),\n",
    "                            output_dim=embedding_size,\n",
    "                            trainable=True)\n",
    "\n",
    "# Defining function that will be encoding sentences using Embedding layer above and two BiLSTMs\n",
    "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"encode_sentence\")\n",
    "def encode_sentence(input_text):\n",
    "    x = embedding_layer(input_text)\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    return x\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"combine_vectors\")\n",
    "def combine_vectors(inputs):\n",
    "    # inputs is a list of two tensors: [premise_encoded, hypothesis_encoded]\n",
    "    premise, hypothesis = inputs\n",
    "    return tf.concat([premise, hypothesis, tf.abs(premise - hypothesis), premise * hypothesis], axis=1)\n",
    "\n",
    "# Encoding both premise and hypothesis\n",
    "premise_encoded = encode_sentence(premise_input)\n",
    "hypothesis_encoded = encode_sentence(hypothesis_input)\n",
    "\n",
    "joined_vector = Lambda(combine_vectors,\n",
    "                      output_shape=(2400,))([premise_encoded, hypothesis_encoded])\n",
    "\n",
    "# Final Dense layer\n",
    "hidden_layer = Dense(hidden_layer_size, activation='relu')(joined_vector)\n",
    "output = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "model = Model(inputs=[premise_input, hypothesis_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a99d3ba7-69f8-4efc-89e8-069c8a1fa631",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "a99d3ba7-69f8-4efc-89e8-069c8a1fa631",
    "outputId": "906b43f6-b2fa-4504-a974-13e306977438"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,653,900</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                           │                        │                │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">962,400</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">962,400</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,162,400</span> │ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,162,400</span> │ bidirectional_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_max_pooling1d_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_max_pooling1d_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2400</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_… │\n",
       "│                           │                        │                │ global_max_pooling1d_… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,229,312</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │      \u001b[38;5;34m3,653,900\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                           │                        │                │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m600\u001b[0m)        │        \u001b[38;5;34m962,400\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m600\u001b[0m)        │        \u001b[38;5;34m962,400\u001b[0m │ embedding_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m600\u001b[0m)        │      \u001b[38;5;34m2,162,400\u001b[0m │ bidirectional_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m600\u001b[0m)        │      \u001b[38;5;34m2,162,400\u001b[0m │ bidirectional_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_max_pooling1d_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_max_pooling1d_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2400\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_… │\n",
       "│                           │                        │                │ global_max_pooling1d_… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │      \u001b[38;5;34m1,229,312\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m513\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,133,325</span> (42.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,133,325\u001b[0m (42.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,133,325</span> (42.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,133,325\u001b[0m (42.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d6bb62a-c7d4-4fcc-90de-0a95f0705625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d6bb62a-c7d4-4fcc-90de-0a95f0705625",
    "outputId": "cd26d26a-7144-4a73-dbaf-aaf948f9d62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 82ms/step - accuracy: 0.5843 - loss: 0.6626 - val_accuracy: 0.6593 - val_loss: 0.6068\n",
      "Epoch 2/2\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - accuracy: 0.7456 - loss: 0.5118 - val_accuracy: 0.6318 - val_loss: 0.6494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x79c805c77950>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_premise_train, X_hypothesis_train], y_train, validation_data=([X_premise_val, X_hypothesis_val], y_val), epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2aa212b-38b1-4489-aa12-259561ba37eb",
   "metadata": {
    "id": "b2aa212b-38b1-4489-aa12-259561ba37eb"
   },
   "outputs": [],
   "source": [
    "# Load testing dataset\n",
    "df_test = pd.read_csv(\"NLI_trial.csv\", quotechar='\"', delimiter=\",\", encoding=\"utf-8\")\n",
    "df_test.columns = [\"premise\", \"hypothesis\", \"label\"]  # Ensure correct column names\n",
    "df_test.dropna(inplace=True)  # Remove missing values\n",
    "\n",
    "# Apply text cleaning for testing dataset\n",
    "df_test[\"premise\"] = df_test[\"premise\"].apply(clean_text)\n",
    "df_test[\"hypothesis\"] = df_test[\"hypothesis\"].apply(clean_text)\n",
    "\n",
    "df_test[\"label\"] = df_test[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "VdD1nrwoxebp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdD1nrwoxebp",
    "outputId": "9bac194f-0c77-4cea-d802-25743413b9e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step\n",
      "Test Accuracy: 0.8000\n",
      "Test F1 Score: 0.8000\n"
     ]
    }
   ],
   "source": [
    "X_hypothesis_test = vectorizer(df_test['hypothesis'].values)\n",
    "X_premise_test = vectorizer(df_test['premise'].values)\n",
    "y_test = df_test['label'].values\n",
    "\n",
    "# Produce predicted probabilities\n",
    "y_pred = model.predict([X_premise_test, X_hypothesis_test])\n",
    "avg = np.mean(y_pred)\n",
    "y_pred = (y_pred > avg).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08cb5e23-9be5-446e-89be-364f8d99b510",
   "metadata": {
    "id": "08cb5e23-9be5-446e-89be-364f8d99b510"
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.flatten()\n",
    "df_predictions = pd.DataFrame({'prediction': y_pred})\n",
    "\n",
    "df_predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7335893-5c29-450d-b9e8-f936297c16b2",
   "metadata": {
    "id": "f7335893-5c29-450d-b9e8-f936297c16b2"
   },
   "outputs": [],
   "source": [
    "# Saving the vectorizer and model\n",
    "model.save(\"bilstm_model.keras\")\n",
    "\n",
    "import pickle\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3aad41-a3de-410b-b30f-be5e3e07e18a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c3aad41-a3de-410b-b30f-be5e3e07e18a",
    "outputId": "d86bb63b-5932-432c-b242-761660106463"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79c804db6700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79c804db6700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 701ms/step\n",
      "Test Accuracy: 0.7800\n",
      "Test F1 Score: 0.7660\n"
     ]
    }
   ],
   "source": [
    "with open('vectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"bilstm_model.keras\")\n",
    "\n",
    "X_premise_loaded = vectorizer(df_test['premise'].values)\n",
    "X_hypothesis_loaded = vectorizer(df_test['hypothesis'].values)\n",
    "\n",
    "# Produce predictions\n",
    "y_pred = loaded_model.predict([X_premise_loaded, X_hypothesis_loaded])\n",
    "avg = np.mean(y_pred)\n",
    "y_pred = (y_pred > avg).astype(int)\n",
    "\n",
    "# Print model's metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142b652-d932-4d7c-8b50-6d5f53d171d2",
   "metadata": {
    "id": "5142b652-d932-4d7c-8b50-6d5f53d171d2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
